{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compte rendu du TP 1 SD-TSIA 211\n",
    "# Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from scipy import sparse\n",
    "from scipy.optimize import check_grad\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse.linalg import svds\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)  Présentation du modèle :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_movielens(filename, minidata=False):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename de la base de donnees\n",
    "    Movielens, par exemple \n",
    "    filename = '~/datasets/ml-100k/u.data'\n",
    "    Elle retourne \n",
    "    R : une matrice utilisateur-item contenant les scores\n",
    "    mask : une matrice valant 1 si il y a un score et 0 sinon\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, dtype=int)\n",
    "\n",
    "    R = sparse.coo_matrix((data[:, 2], (data[:, 0] - 1, data[:, 1] - 1)),\n",
    "                          dtype=float)\n",
    "    R = R.toarray()  # not optimized for big data\n",
    "\n",
    "    # code la fonction 1_K\n",
    "    mask = sparse.coo_matrix((np.ones(data[:, 2].shape),\n",
    "                              (data[:, 0] - 1, data[:, 1] - 1)), dtype=bool)\n",
    "    mask = mask.toarray()  # not optimized for big data\n",
    "\n",
    "    if minidata is True:\n",
    "        R = R[0:100, 0:200].copy()\n",
    "        mask = mask[0:100, 0:200].copy()\n",
    "\n",
    "    return R, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "filename = \"u.data\"\n",
    "R, mask = load_movielens(filename)\n",
    "n, k = R.shape\n",
    "print(n, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient effectivement une matrice de dimensions 943 x 1682.\n",
    "L'option mindata si mise à True retourne uniquement une partie des données de dimensions 100 x 200 pour R et mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre d'utilisateur est : 943\n",
      "Le nombre total de notes est : 100000\n"
     ]
    }
   ],
   "source": [
    "print(\"Le nombre d'utilisateur est : \" + str(n))\n",
    "print(\"Le nombre total de notes est : \" + str(sum(sum(mask))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Il existe 943 utilisateurs et 1682 films référencés dans la base de données.\n",
    "Le nombre total de notes = 100 000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.3 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <strong> La fonction objectif n'est pas convexe : </strong>\n",
    "On prend le cas scalaire où $\\rho = 0 $\n",
    "la fontion objectif devient alors : $f(p,q) = \\frac{1}{2}*(r-pq)^2 $<br\\>\n",
    "On obtient alors: $\\nabla^2 f(p,q) =  \\begin{bmatrix} q^2 & 2qp-r \\\\ 2qp-r & p^2 \\end{bmatrix} $\n",
    "; Pour $ x = \\begin{bmatrix}p\\\\q\\end{bmatrix}  $ on a <br\\>$x^T\\nabla^2 f(p,q) x = 2pq(3pq-r) $ tel que pour $ q = p = \\frac{\\sqrt(|r|)}{\\sqrt(5)}$ on aura $x^T\\nabla^2 f(p,q) x = -\\frac{4}{25}r² < 0  $ <br/>\n",
    "Alors $\\nabla^2 f$ n'est pas positive dans ce cas donc on peut généraliser ce cas et dire que la fonction objectif n'est pas convexe en (P,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Calculer le gradient de la fonction objectif </strong>\n",
    "\n",
    "On a : $g(P,Q)=\\frac{1}{2} \\|\\mathcal{1_K \\circ (R - QP)}\\|^2_F+\\rho\\|\\mathcal{Q}\\|^2_F+\\rho\\|\\mathcal{P}\\|^2_F $\n",
    "<br\\>Alors : $\\nabla_Q f(P,Q) = \\rho Q - (\\mathcal{1_K \\circ (R-QP)}\\ ) P^T $ <br\\> et \n",
    "$\\nabla_P f(P,Q) = \\rho P - Q^T(\\mathcal{1_K \\circ (R-QP)}\\ )  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Trouver P quand $Q_0$ est fixé :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1:\n",
    "Le gradient de la fonction objectif devient alors : $\\nabla g(P) = \\rho P - {Q^0}^T(\\mathbb{1}_K \\circ (R - Q^0P))$ <br\\>\n",
    "$ \\nabla^{2} g(P) =  \\mathbb{1}_K\\circ(Q^{0})^{T}Q^{0} + \\rho Id $ or $\\rho = 0.3 > 0 $  , alors $\\nabla^{2} g(P)$ est définie positive <br/> alors la fonction objectif à Q fixé est convexe <br\\>\n",
    "$ L_0 = \\rho + \\|Q_0^T Q_0\\|_F $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(P, Q0, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme simplifie.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q0 : une matrice de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction en (P,Q0)\n",
    "    grad_P : le gradient par rapport a P\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q0.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2) / 2. + rho / 2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = rho * P - np.dot(np.transpose(Q0), tmp)\n",
    "\n",
    "    return val, grad_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 4\n",
    "epsi = 700\n",
    "rho = 0.3\n",
    "Q0, singval, P0 = svds(R, k=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(X):\n",
    "    S = X.reshape(c, k)\n",
    "    func, grad = objective(S, Q0, R, mask, rho)\n",
    "    return func\n",
    "\n",
    "\n",
    "def grad(X):\n",
    "    S = X.reshape(c, k)\n",
    "    func, grad = objective(S, Q0, R, mask, rho)\n",
    "    return np.ravel(objective)\n",
    "\n",
    "#print(check_grad(func, grad, np.ravel(P0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gradient(g, P0, gamma, epsilon):\n",
    "    '''\n",
    "    Calcule le gradient et le point minimal de la fonction g\n",
    "    Entrées :\n",
    "    g : foncrion objectif\n",
    "    P : la variable matricielle de taille C x I\n",
    "    gamma : pas de la méthode de descente\n",
    "    epsilon : condition d'arrêt\n",
    "\n",
    "    Sorties :\n",
    "    val : le gradient de g \n",
    "    x_k : le min de la fonction g \n",
    "    '''\n",
    "    x_k = P0\n",
    "    val, grad = g(P0)\n",
    "    while(np.linalg.norm(grad, ord='fro') > epsilon):\n",
    "        x_k = x_k - gamma * grad\n",
    "        val, grad = g(x_k)\n",
    "    return val, x_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369551.549915\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1\n",
    "L0 = rho + np.linalg.norm(np.transpose(Q0).dot(Q0), ord='fro')\n",
    "gamma = 1 / L0\n",
    "\n",
    "\n",
    "def g(P): return objective(P, Q0, R, mask, rho)\n",
    "\n",
    "\n",
    "val, m = Gradient(g, P0, gamma, epsilon)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raffinements algorithmiques pour le problème à $Q_0$ fixé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question 3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def armijo(g, P, a, b, beta):\n",
    "    '''\n",
    "    La fonction de recherche linéaire d'Armijo pour déterminer b*a^l a.k.a gamma\n",
    "    prend en entrée : \n",
    "    g : la fonction objectif\n",
    "    P : la variable matricielle de taille C x I\n",
    "    a : tel que a dans [0,1]\n",
    "    b : tel que b > 0\n",
    "    beta : tel que beta dans [0,1]\n",
    "\n",
    "    Sortie \n",
    "    gamma : le pas de de la méthode du gradient descendant\n",
    "    '''\n",
    "    gP, gradP = g(P)  # Récupérer le gradient de la fonction objectif en P\n",
    "\n",
    "    gamma = b\n",
    "    x = P - gamma * gradP\n",
    "    gx, gradx = g(x)\n",
    "    while (gx > (gP + beta * np.sum(gradP * (x - P)))):\n",
    "        gamma = gamma * a\n",
    "        x = P - gamma * gradP\n",
    "        gx, gradx = g(x)\n",
    "\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gradient_Line_Search(g, P0, gamma0, epsilon):\n",
    "    '''\n",
    "    La fonction retourne le gradient de g et un minimiseur de g \n",
    "    Entrées:\n",
    "    g : fonction objectif\n",
    "    P0 : La variable matricielle de taille C x I\n",
    "    epsilon : facteur de précision\n",
    "    gamma0 : pas initial de la méthode Gradient Linear Search\n",
    "\n",
    "    Sorties:\n",
    "    gradP : le gradient de g\n",
    "    val : min de g\n",
    "    '''\n",
    "    [val, gradP] = objective(P0, Q0, R, mask, rho)\n",
    "    while(np.linalg.norm(gradP, ord='fro') > epsilon):\n",
    "\n",
    "        P0 = P0 - gamma0 * gradP\n",
    "        gamma0 = armijo(g, P0, 0.5, 2 * gamma0, 0.5)\n",
    "        [val, gradP] = g(P0)\n",
    "\n",
    "    return (val, gradP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_ls, gradP_ls = Gradient_Line_Search(g, P0, 0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valeur obtenue par la méthode armijo's line search  est 369551.402967\n"
     ]
    }
   ],
   "source": [
    "print(\"La valeur obtenue par la méthode armijo's line search  est \" + str(val_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g(P) = \\frac{1}{2}\\|\\mathbb{1}_{K}\\circ(R-Q^{0}P)\\|^2_F + \\frac{\\rho}{2}\\|Q^{0}\\|^2_F + \\frac{\\rho}{2}\\|P\\|^2_F$\n",
    "  \n",
    "$\n",
    "= \\frac{1}{2}P^T\\left((Q^0)^{T}(\\mathbb{1}_{K}\\circ(\\mathbb{1}_{K})^{T})Q^0 + \\rho Id\\right)P - \\frac{1}{2}((\\mathbb{1}_{K}\\circ(R))^{T}Q^0P + P^{T}(Q^0)^{T}(\\mathbb{1}_{K}\\circ(R))) + \\frac{1}{2}((\\mathbb{1}_{K}\\circ(R))^{T}(\\mathbb{1}_{K}\\circ(R)) + \\rho(Q^0)^{T}Q^0) \\\\\n",
    "$\n",
    "\n",
    "or on a :   \n",
    "$\\begin{align*}\n",
    "(\\mathbb{1}_{K}\\circ(R))^TQ^0P &= \\langle (\\mathbb{1}_{K}\\circ(R)), Q^0P \\rangle \\\\\n",
    "&= \\langle Q^0P, (\\mathbb{1}_{K}\\circ(R)) \\rangle \\\\\n",
    "&= P^{T}(Q^0)^{T}(\\mathbb{1}_{K}\\circ(R))\n",
    "\\end{align*}$  \n",
    "\n",
    "donc:\n",
    "$g(P) = \\frac{1}{2}P^T\\left(\\mathbb{1d}_{K}\\circ(Q^0)^TQ^0 + \\rho Id\\right)P - \\mathbb{1d}_K\\circ R^TQ^0P + \\frac{1}{2}\\left(\\mathbb{1d}_K\\circ R^TR + \\rho(Q^0)^TQ^0\\right)$\n",
    "\n",
    "qui est de la forme : $\\frac{1}{2}P^TAP + BP + C$ \n",
    "\n",
    "avec $A = \\left(\\mathbb{1d}_{K}\\circ(Q^0)^TQ^0 + \\rho Id\\right)$ <br\\>\n",
    "$B = -\\mathbb{1d}_K\\circ R^TQ^0 $<br\\> \n",
    "$C = \\frac{1}{2}\\left(\\mathbb{1d}_K\\circ R^TR + \\rho(Q^0)^TQ^0\\right)$\n",
    "\n",
    "<br\\> Comme $\\rho>0$: alors la matrice $A$ est définie positive.\n",
    "\n",
    "\n",
    "<br\\>On utilise donc la méthode du gradient conjugué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientConjuge(g, P0, Q0, epsilon):\n",
    "    '''\n",
    "    La fonction retourne le gradient de g et un minimiseur de g en appliquant la méthode du gradient conjugué\n",
    "    Entrées:\n",
    "    g : fonction objectif\n",
    "    P0 : La variable matricielle de taille C x I\n",
    "    Q0 : La variable matricielle de taille U x C\n",
    "    epsilon : Facteur de précision\n",
    "\n",
    "    Sorties:\n",
    "    P : le gradient de g\n",
    "    g(P)[0] : min de g\n",
    "    '''\n",
    "    grad_gP = g(P0)[1]\n",
    "    direction = - grad_gP\n",
    "    prod = rho * direction + np.transpose(Q0).dot(mask * (Q0.dot(direction)))\n",
    "    # la matrice A fois d\n",
    "    s = - np.sum(direction * grad_gP) / np.sum(direction * prod)\n",
    "    P = P0 + s * direction\n",
    "    while(np.linalg.norm(grad_gP) > epsilon):\n",
    "        grad_gP = g(P)[1]\n",
    "        b = np.sum(grad_gP * prod) / np.sum(direction * prod)\n",
    "        direction = - grad_gP + b * direction\n",
    "        prod = rho * direction + Q0.T.dot(mask * (Q0.dot(direction)))\n",
    "        s = - np.sum(direction * grad_gP) / np.sum(direction * prod)\n",
    "        P = P + s * direction\n",
    "    return P, g(P)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369550.62773\n"
     ]
    }
   ],
   "source": [
    "p, val = GradientConjuge(g, P0, Q0, 1)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps d'excecution de gradient pas constant = 0.672619836001104\n",
      "Le temps d'excecution de gradient line search est = 0.7108894660013902\n",
      "Le temps d'excecution de gradient conjugué est = 0.2825142660003621\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "[val_opt, P_opt] = Gradient(g, P0, gamma, epsilon)\n",
    "end = timer()\n",
    "grad_pas_constant = end - start\n",
    "\n",
    "start = timer()\n",
    "val_ls, gradP_ls = Gradient_Line_Search(g, P0, 0.5, 1)\n",
    "end = timer()\n",
    "gradient_ls = end - start\n",
    "\n",
    "\n",
    "start = timer()\n",
    "p, val = GradientConjuge(g, P0, Q0, 1)\n",
    "end = timer()\n",
    "gradient_conj = end - start\n",
    "print(\"Le temps d'excecution de gradient pas constant = \" + str(grad_pas_constant))\n",
    "print(\"Le temps d'excecution de gradient line search est = \" + str(gradient_ls))\n",
    "print(\"Le temps d'excecution de gradient conjugué est = \" + str(gradient_conj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution du problème complet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_objective(P, Q, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme complet.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q : la variable matricielle de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    grad_Q : le gradient par rapport a Q\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2) / 2. + rho / 2. * (np.sum(Q ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = rho * P - Q.T.dot(tmp)\n",
    "\n",
    "    grad_Q = rho * Q - tmp.dot(P.T)\n",
    "    return val, grad_P, grad_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ArmijoGeneralized(g, P, Q, a, b, beta):\n",
    "    '''\n",
    "    La fonction de recherche linéaire d'Armijo pour déterminer b*a^l a.k.a gamma\n",
    "    prend en entrée : \n",
    "    g : la fonction objectif\n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q : la variable matricielle de taille U x C\n",
    "    a : tel que a dans [0,1]\n",
    "    b : tel que b > 0\n",
    "    beta : tel que beta dans [0,1]\n",
    "\n",
    "    Sortie \n",
    "    gamma : le pas de de la méthode du gradient descendant\n",
    "    '''\n",
    "    val, grad_P, grad_Q = g(P, Q)\n",
    "    gamma = b\n",
    "    P_plus = P - gamma * grad_P\n",
    "    Q_plus = Q - gamma * grad_Q\n",
    "    while (g(P_plus, Q_plus)[0] > val + beta * np.sum(grad_P * (P_plus - P)) + beta * np.sum(grad_Q * (Q_plus - Q))):\n",
    "        gamma *= a\n",
    "        P_plus = P - gamma * grad_P\n",
    "        Q_plus = Q - gamma * grad_Q\n",
    "\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gradient_Line_Search_Generalized(g, P0, Q0, gamma0, epsilon):\n",
    "    '''\n",
    "    Retourne le min de la fonction objectif généralisée \n",
    "    Entrées:\n",
    "    g_gen : fonction objectif généralisée\n",
    "    P0 : la variable matricielle de taille C x I\n",
    "    Q0 : la variable matricielle de taille U x C\n",
    "    gamma0 : Pas initial\n",
    "    epsilon : facteur de précision\n",
    "    Sortie:\n",
    "    val : valeur minimale\n",
    "    '''\n",
    "    P = P0\n",
    "    Q = Q0\n",
    "    val, grad_P, grad_Q = g(P, Q)\n",
    "    gamma = ArmijoGeneralized(g, P, Q, 0.5, 2 * gamma0, 0.5)\n",
    "\n",
    "    while (np.linalg.norm(grad_P) > epsilon or np.linalg.norm(grad_Q) > epsilon):\n",
    "        P = P - gamma * grad_P\n",
    "        Q = Q - gamma * grad_Q\n",
    "        gamma = ArmijoGeneralized(g, P, Q, 0.5, 2 * gamma, 0.5)\n",
    "        val, grad_P, grad_Q = g(P, Q)\n",
    "\n",
    "    return P, Q, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.26620423,  0.02080478,  0.65317844, ..., -0.04728094,\n",
       "         -0.00551023,  0.07793016],\n",
       "        [ 0.38685675, -0.70719179, -0.15535588, ...,  0.05141169,\n",
       "         -0.01844841,  0.00492953],\n",
       "        [-1.01435488,  0.00851166, -0.82183963, ..., -0.05219049,\n",
       "          0.01750809,  0.02657223],\n",
       "        [ 2.02208148,  1.53540481,  1.42863097, ...,  0.02696574,\n",
       "          0.13826988,  0.14081172]]),\n",
       " array([[ 0.80045223,  0.31817446,  0.14528985,  2.12185149],\n",
       "        [ 0.065585  ,  0.94742262, -0.87234076,  1.17450003],\n",
       "        [-0.35266131,  0.60695575, -0.62291355,  0.96416904],\n",
       "        ..., \n",
       "        [ 0.30694508,  0.31333343, -0.99334199,  1.40814168],\n",
       "        [-0.92097246,  0.17282727,  0.40038025,  2.14151306],\n",
       "        [ 0.72988517, -0.61061147, -0.35498355,  1.93663952]]),\n",
       " 44814.266408267606,\n",
       " 2.8758017210020625)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon=100\n",
    "gamma0 = 1\n",
    "t1=timer()\n",
    "P, Q, val = Gradient_Line_Search_Generalized(lambda P,Q : total_objective(P, Q, R, mask, rho), P0, Q0, gamma0, epsi)\n",
    "t2=timer()\n",
    "P,Q,val,t2-t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Soit $k \\in \\mathbb{N}^*$.\n",
    "\n",
    "On a  : pour tout $ P, \\quad g(P_{k+1}, Q_k) \\leq g(P, Q_k)$ donc :$ g(P_{k+1}, Q_k) \\leq g(P_k, Q_k)$\n",
    "\n",
    "\n",
    "et on a : pour tout $ Q, \\quad g(P_{k+1}, Q_{k+1}) \\leq g(P_{k+1}, Q) $\n",
    "donc : $ g(P_{k+1}, Q_{k+1}) \\leq g(P_{k+1}, Q_k) $\n",
    "\n",
    "finalement: pour tout $k \\in \\mathbb{N}^*, \\quad g(P_{k+1}, Q_{k+1}) \\leq g(P_k, Q_k)$\n",
    "\n",
    "Conclusion : $(g(P_k,Q_k))$ $ k\\in\\mathbb{N}^* $ est décroissante.\n",
    "Et puisque $ 0 \\leq g(P_k,Q_k)$ alors la suite $(g(P_k,Q_k))$ est décroissante et minorée donc elle converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective_Q(P0, Q, R, mask, rho):\n",
    "\n",
    "    tmp = (R - Q.dot(P0)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2) / 2. + rho / 2. * (np.sum(Q ** 2) + np.sum(P0 ** 2))\n",
    "\n",
    "    grad_Q = rho * Q - np.dot(tmp, np.transpose(P0))\n",
    "\n",
    "    return val, grad_Q\n",
    "\n",
    "def gradientLineSearch(g, P0, gamma0, epsilon):\n",
    "    \n",
    "    P = P0\n",
    "    gP, grad_gP = g(P)\n",
    "    gamma = armijo(g, P, 0.5, 2*gamma0, 0.5)\n",
    "    \n",
    "    while (np.linalg.norm(grad_gP) > epsilon):\n",
    "        P = P - gamma * grad_gP\n",
    "        gamma = armijo(g, P, 0.5, 2*gamma, 0.5)\n",
    "        gP, grad_gP = g(P)\n",
    "    \n",
    "    return P, gP  \n",
    "\n",
    "def LS_Alt(P0, Q0, R, mask, rho, gamma, epsilon):\n",
    "    P = P0\n",
    "    Q = Q0\n",
    "    val, gradP, gradQ = total_objective(P, Q, R, mask, rho)\n",
    "    while (np.linalg.norm(gradP) > epsilon) or (np.linalg.norm(gradQ) > epsilon):\n",
    "        P, val = gradientLineSearch(lambda P: objective(\n",
    "            P, Q, R, mask, rho), P, gamma, epsilon)\n",
    "\n",
    "        Q, val = gradientLineSearch(lambda Q: objective_Q(\n",
    "            P, Q, R, mask, rho), Q,  gamma, epsilon)\n",
    "\n",
    "        val, gradP, gradQ = total_objective(P, Q, R, mask, rho)\n",
    "\n",
    "\n",
    "    return P, Q, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.4 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  2.23804388e+00,   4.49704424e-01,   6.77817742e+00, ...,\n",
       "          -1.32622117e-01,   1.07596505e-02,   2.43428224e-01],\n",
       "        [ -3.20717528e+00,  -1.18641511e+01,  -2.21042079e+00, ...,\n",
       "           1.01359068e-01,  -8.64003283e-02,  -4.97074436e-02],\n",
       "        [ -1.85841932e+01,  -1.49497760e+00,  -6.10605290e+00, ...,\n",
       "          -9.57335320e-02,   2.24813597e-02,   4.33986589e-02],\n",
       "        [  5.34530804e+01,   1.95997311e+01,   1.11053104e+01, ...,\n",
       "           1.69422898e-02,   1.84664476e-01,   1.76733021e-01]]),\n",
       " array([[ 0.08074965,  0.04744437,  0.01355601,  0.11908643],\n",
       "        [ 0.03060962,  0.13622213, -0.06445243,  0.0510773 ],\n",
       "        [-0.03420024,  0.13393793,  0.00036797,  0.05998684],\n",
       "        ..., \n",
       "        [ 0.07428433,  0.0557645 , -0.06364925,  0.07305806],\n",
       "        [-0.18829466,  0.04628578,  0.05410047,  0.09841898],\n",
       "        [ 0.12224065, -0.09809558, -0.01099657,  0.09028144]]),\n",
       " 234300.14411245758,\n",
       " 16.293220187999395)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 100\n",
    "t1=timer()\n",
    "minLS_P, minLS_Q, val = LS_Alt(P0, Q0, R, mask, rho, gamma, epsi)\n",
    "t2=timer()\n",
    "minLS_P,minLS_Q,val,t2-t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7224195178620176"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1=Q.dot(P)[300]\n",
    "score = max(R1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrouvons le film à recommender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(R1)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le film à recommender est le film d'id 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
